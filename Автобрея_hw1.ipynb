{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тональность отзывов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сайт -- bookmix, материал -- рецензии, потому что они длинные и интересно, что получится"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Улучшения\n",
    "\n",
    "Хорошо бы подумать о них до написания основного кода.\n",
    "1. если взять больше материала, точность должна быть выше. \n",
    "2. однозвёздочных рецензий мало. можно добавить к ним двухзвёздочные и посмотреть, что получится. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Скачивание отзывов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вначале соберём отзывы. Поскольку можно все 70 нужных ссылок получить одним обходом сайта, писать для этого функцию нет необходимости. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "ua = UserAgent(verify_ssl=False)\n",
    "session = requests.session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [10:29<00:00,  1.26s/it]\n"
     ]
    }
   ],
   "source": [
    "negative_words = []\n",
    "positive_words = []\n",
    "begin = 0\n",
    "for i in tqdm(range(500)):#while len(negative_words) < 35 or len(positive_words) < 35:\n",
    "    begin += 10\n",
    "    url = f'https://bookmix.ru/reviews.phtml?option=all&begin={begin}&num_point=10&num_points=10'\n",
    "    req = session.get(url, headers={'User-Agent': ua.random})\n",
    "    req.encoding = 'utf-8'\n",
    "    page = req.text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    titles = soup.find_all('div', {'class': 'universal-blocks'})\n",
    "    for title in titles:\n",
    "        rate = title.find('div', {'class': 'rating'})\n",
    "        if rate:\n",
    "            rate = rate.attrs['class'][-1][-1]\n",
    "            if rate == '1' or rate == '2':\n",
    "                href = title.find('h5').find('a').attrs['href']\n",
    "                negative_words.append(href)\n",
    "            elif rate == '5':# and len(positive_words) < 35:\n",
    "                href = title.find('h5').find('a').attrs['href']\n",
    "                positive_words.append(href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2645"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negative_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку количество негативных и позитивных отзывов очень разное, можно взять по 260 тех и других на обучение и по 30 на проверку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Токенизация и лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from collections import Counter\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts(hrefs):\n",
    "    words = []\n",
    "    for href in hrefs: #tqdm(hrefs):\n",
    "        href = f'https://bookmix.ru/{href}'\n",
    "        req = session.get(href, headers={'User-Agent': ua.random})\n",
    "        req.encoding = 'utf-8'\n",
    "        req = req.text\n",
    "        req = BeautifulSoup(req, 'html.parser')\n",
    "        text = req.find('div', {'class': 'universal-blocks-content'}).text.lower()\n",
    "        text = word_tokenize(text)\n",
    "        for word in text:\n",
    "            if word.isalpha():\n",
    "                words.append(morph.parse(word)[0][2]) #добаляем в словарь лемму\n",
    "    words = dict(Counter(words))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 260/260 [05:34<00:00,  1.29s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 260/260 [06:49<00:00,  1.58s/it]\n"
     ]
    }
   ],
   "source": [
    "positive_dict = get_texts(positive_words[:260])\n",
    "negative_dict = get_texts(negative_words[:260])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13816"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14778"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negative_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Множества и исключение шума"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_set(some_dict):\n",
    "    word_set = []\n",
    "    for word, freq in some_dict.items():\n",
    "        if freq > 2:\n",
    "            word_set.append(word)\n",
    "    word_set = set(word_set)\n",
    "    return word_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_set = make_set(positive_dict) \n",
    "negative_set = make_set(negative_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_set = positive_set & negative_set\n",
    "positive_set = positive_set.difference(all_set)\n",
    "negative_set = negative_set.difference(all_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Функция для определения тональности отзыва"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tone(href):\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    words = get_texts([href,])\n",
    "    for word, freq in words.items():\n",
    "        if word in positive_set:\n",
    "            pos += 1*freq\n",
    "        elif word in negative_set:\n",
    "            neg += 1*freq\n",
    "    if pos > neg:\n",
    "        result = 'pos'\n",
    "    elif pos < neg:\n",
    "        result = 'neg'\n",
    "    else:\n",
    "        result = 'nonloso'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_tone(positive_hrefs, negative_hrefs):\n",
    "    detected_tone = []\n",
    "    real_tone = []\n",
    "    for text in positive_hrefs:\n",
    "        detected_tone.append(tone(text))\n",
    "        real_tone.append('pos')\n",
    "    for text in negative_hrefs:\n",
    "        detected_tone.append(tone(text))\n",
    "        real_tone.append('neg')\n",
    "    return accuracy_score(detected_tone, real_tone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7619047619047619"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_tone(positive_words[260:292], negative_words[260:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так себе точность, но:\n",
    "1) с откидыванием слов, которые встретились один или три раза, всё становится хуже. \n",
    "2) Можно было бы увеличить объём текстов за счёт обхода всего корпуса, но в задании и так сказано, что минимум -- по 30.\n",
    "3) Книжные рецензии -- тексты длинные, и предположительно могут быть устроены сложнее, чем короткие отзывы\n",
    "4) Можно наткнуться на сарказм не слишком редко, а такие штуки плохо поддаются анализу на основе только слов"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
