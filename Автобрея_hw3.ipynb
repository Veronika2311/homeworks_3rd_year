{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Автобрея_hw3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Veronika2311/homeworks_3rd_year/blob/main/%D0%90%D0%B2%D1%82%D0%BE%D0%B1%D1%80%D0%B5%D1%8F_hw3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiRgbe1y3QTM"
      },
      "source": [
        "# Gensim, Mallet, TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhsPdNf_3QVj",
        "outputId": "ef20c06a-0f57-4545-975a-d28df523beb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1Viz0gp3QWO",
        "outputId": "e4983689-28cf-4563-ae0a-92f9f57fee48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "!pip install spacy"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (50.3.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE7j-Bro3QXw",
        "outputId": "7b47d5e9-a852-4a51-fc23-b9034f67f81d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "!pip  install pyLDAvis"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyLDAvis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/3a/af82e070a8a96e13217c8f362f9a73e82d61ac8fff3a2561946a97f96266/pyLDAvis-2.1.2.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.35.1)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.1.2)\n",
            "Requirement already satisfied: joblib>=0.8.4 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (2.11.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (2.7.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (3.6.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Collecting funcy\n",
            "  Downloading https://files.pythonhosted.org/packages/66/89/479de0afbbfb98d1c4b887936808764627300208bb771fcd823403645a36/funcy-1.15-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.0->pyLDAvis) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.0->pyLDAvis) (2.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.7.2->pyLDAvis) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (50.3.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.9.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (20.2.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (8.5.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.15.0)\n",
            "Building wheels for collected packages: pyLDAvis\n",
            "  Building wheel for pyLDAvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-2.1.2-py2.py3-none-any.whl size=97712 sha256=8ba77ca94c37f638988f254b8e2f7b7a8009076cfa31a75ab3a88f4bad7d5804\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/71/24/513a99e58bb6b8465bae4d2d5e9dba8f0bef8179e3051ac414\n",
            "Successfully built pyLDAvis\n",
            "Installing collected packages: funcy, pyLDAvis\n",
            "Successfully installed funcy-1.15 pyLDAvis-2.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piQUhNA_3QZv",
        "outputId": "0c4aae58-df2f-421d-d84d-6edd20289a2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk; nltk.download('stopwords')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjoCitYK3QaH",
        "outputId": "751ca340-43ff-4dd9-cbe9-9d4d16cb4f66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (50.3.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.2.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LW6HDG513Qbq"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "\n",
        "# Gensim\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "# spacy for lemmatization\n",
        "import spacy\n",
        "\n",
        "# Plotting tools\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim  # don't skip this\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Enable logging for gensim - optional\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7skr96dM3Qb-"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqVgl42G3QcQ",
        "outputId": "436d0177-eeb0-4dca-9573-5ac6a36aba4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "df = pd.read_json('https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json')\n",
        "print(df.target_names.unique())\n",
        "df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['rec.autos' 'comp.sys.mac.hardware' 'comp.graphics' 'sci.space'\n",
            " 'talk.politics.guns' 'sci.med' 'comp.sys.ibm.pc.hardware'\n",
            " 'comp.os.ms-windows.misc' 'rec.motorcycles' 'talk.religion.misc'\n",
            " 'misc.forsale' 'alt.atheism' 'sci.electronics' 'comp.windows.x'\n",
            " 'rec.sport.hockey' 'rec.sport.baseball' 'soc.religion.christian'\n",
            " 'talk.politics.mideast' 'talk.politics.misc' 'sci.crypt']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>target</th>\n",
              "      <th>target_names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
              "      <td>7</td>\n",
              "      <td>rec.autos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
              "      <td>14</td>\n",
              "      <td>sci.space</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content  ...           target_names\n",
              "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...  ...              rec.autos\n",
              "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...  ...  comp.sys.mac.hardware\n",
              "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...  ...  comp.sys.mac.hardware\n",
              "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...  ...          comp.graphics\n",
              "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...  ...              sci.space\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLeY2QG33Qd1",
        "outputId": "2ec6df28-ed2d-465f-cadf-9fd7432e2bd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Convert to list\n",
        "data = df.content.values.tolist()\n",
        "\n",
        "\n",
        "#YOURCODE\n",
        "\n",
        "# Remove Emails\n",
        "data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
        "\n",
        "# Remove new line characters\n",
        "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
        "\n",
        "# Remove distracting single quotes\n",
        "data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
        "\n",
        "pprint(data[:1])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['From: (wheres my thing) Subject: WHAT car is this!? Nntp-Posting-Host: '\n",
            " 'rac3.wam.umd.edu Organization: University of Maryland, College Park Lines: '\n",
            " '15 I was wondering if anyone out there could enlighten me on this car I saw '\n",
            " 'the other day. It was a 2-door sports car, looked to be from the late 60s/ '\n",
            " 'early 70s. It was called a Bricklin. The doors were really small. In '\n",
            " 'addition, the front bumper was separate from the rest of the body. This is '\n",
            " 'all I know. If anyone can tellme a model name, engine specs, years of '\n",
            " 'production, where this car is made, history, or whatever info you have on '\n",
            " 'this funky looking car, please e-mail. Thanks, - IL ---- brought to you by '\n",
            " 'your neighborhood Lerxst ---- ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdxA55eK3QeH",
        "outputId": "2e29faa1-0574-4587-cf59-57a7f6d846a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#tikenize\n",
        "\n",
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
        "\n",
        "data_words = list(sent_to_words(data))\n",
        "\n",
        "print(data_words[:1])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['from', 'wheres', 'my', 'thing', 'subject', 'what', 'car', 'is', 'this', 'nntp', 'posting', 'host', 'rac', 'wam', 'umd', 'edu', 'organization', 'university', 'of', 'maryland', 'college', 'park', 'lines', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'saw', 'the', 'other', 'day', 'it', 'was', 'door', 'sports', 'car', 'looked', 'to', 'be', 'from', 'the', 'late', 'early', 'it', 'was', 'called', 'bricklin', 'the', 'doors', 'were', 'really', 'small', 'in', 'addition', 'the', 'front', 'bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', 'this', 'is', 'all', 'know', 'if', 'anyone', 'can', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'of', 'production', 'where', 'this', 'car', 'is', 'made', 'history', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', 'please', 'mail', 'thanks', 'il', 'brought', 'to', 'you', 'by', 'your', 'neighborhood', 'lerxst']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6Oj4QpE3Qf9"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SODQtWsF3QgO",
        "outputId": "aabd806c-0bc4-4ce0-b612-ac9e579c8e3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Build the bigram and trigram models\n",
        "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
        "\n",
        "# Faster way to get a sentence clubbed as a trigram/bigram\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "\n",
        "# See trigram example\n",
        "print(trigram_mod[bigram_mod[data_words[0]]])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['from', 'wheres', 'my', 'thing', 'subject', 'what', 'car', 'is', 'this', 'nntp_posting_host', 'rac_wam_umd_edu', 'organization', 'university', 'of', 'maryland_college_park', 'lines', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'saw', 'the', 'other', 'day', 'it', 'was', 'door', 'sports', 'car', 'looked', 'to', 'be', 'from', 'the', 'late', 'early', 'it', 'was', 'called', 'bricklin', 'the', 'doors', 'were', 'really', 'small', 'in', 'addition', 'the', 'front_bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', 'this', 'is', 'all', 'know', 'if', 'anyone', 'can', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'of', 'production', 'where', 'this', 'car', 'is', 'made', 'history', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', 'please', 'mail', 'thanks', 'il', 'brought', 'to', 'you', 'by', 'your', 'neighborhood', 'lerxst']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urQPAlS43Qgg"
      },
      "source": [
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "\n",
        "def make_bigrams(texts):\n",
        "    return [bigram_mod[doc] for doc in texts]\n",
        "\n",
        "def make_trigrams(texts):\n",
        "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_out"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp_QxABl3Qhh",
        "outputId": "0097bc86-5229-415d-82d5-08693271d1fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (50.3.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.2.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Vr2BrcWN3QiD",
        "outputId": "cd5b671e-199c-45ed-b546-d3bccdc8d0c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Remove Stop Words\n",
        "data_words_nostops = remove_stopwords(data_words)\n",
        "\n",
        "# Form Bigrams\n",
        "data_words_bigrams = make_bigrams(data_words_nostops)\n",
        "\n",
        "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
        "# python3 -m spacy download en\n",
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "\n",
        "# Do lemmatization keeping only noun, adj, vb, adv\n",
        "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "\n",
        "print(data_lemmatized[:1])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['where', 'thing', 'car', 'nntp_poste', 'host', 'park', 'line', 'wonder', 'could', 'enlighten', 'car', 'see', 'day', 'door', 'sport', 'car', 'look', 'late', 'early', 'call', 'bricklin', 'door', 'really', 'small', 'addition', 'separate', 'rest', 'body', 'know', 'tellme', 'model', 'name', 'engine', 'year', 'production', 'car', 'make', 'history', 'info', 'funky', 'look', 'car', 'mail', 'thank', 'bring', 'neighborhood', 'lerxst']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BI40jJwY3Qje"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Htl1dWoH3Qjx",
        "outputId": "8102113b-06d8-409f-d4ee-5f25cf8d0211",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Create Dictionary\n",
        "id2word = corpora.Dictionary(data_lemmatized)\n",
        "\n",
        "# Create Corpus\n",
        "texts = data_lemmatized\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "# View\n",
        "print(corpus[:1])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 5), (6, 1), (7, 1), (8, 2), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 2), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1)]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4hKWZsd-7Ja"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9SXrL1GCE0w"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZB4rrL6EdAi"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfCUPHggEDdM"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-5WaNzg3Qlb"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJU9rLTvPLlD"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbOSDNsWPP9n"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxhSa1Fk3Qlp"
      },
      "source": [
        "Создайте функцию или серию функций, через которую будет удобно подобрать оптимальное число групп - 1 балл за нахождение оптимального числа групп, 1 балл - если этобудет не руками, а через функцию\n",
        "\n",
        "Как вы знаете, gensim считает, что каждый текст содержит несколько топиков, но на следвующем этапе вам будет надо создать функцию, которая будет для каждого текста определять один широкий топик, самый главный.\n",
        "\n",
        "Мв предлагаем сделать это так: создайте счётчик, и каждый раз, когда в тексте будет встречаться одно из слов, соответсвующих данной теме, добавляйте к счетчику его вес. 2 балла\n",
        "\n",
        "После того, как у вас получится какое-то количество групп (наборов текстов с общим топиком). Внутри каждой из этих групп посчитайте тф_идф для каждого текста (Т. е. возьмите все тексты с одинаковой темой за ваш корпус и посчитайте для каждого из этих текстов тф_идф). 3 балла\n",
        "\n",
        "Каждому тексту определите слова с пятью самыми высокими тф_идф и запишите их в таблицу\n",
        "\n",
        "вывод - excel, csv или pandas таблица с текстом, его широким топиком по дженсиму и 5 тф_идф словами для этого текста - 1 балл\n",
        "\n",
        "Логичность и красота кода - 1 балл\n",
        "\n",
        "ещё один бонус балл: описать как работает coherence score (не успели обсудить на паре) на русском - словами"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcbEL5x9SVEw"
      },
      "source": [
        "import tqdm"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wECtd-uuPecc"
      },
      "source": [
        "def choose_score(start, number, rate, corpus, id2word, data_lemmatized):\n",
        "    #os.environ['MALLET_HOME'] = 'D:/mallet-2.0.8/mallet-2.0.8'\n",
        "    #mallet_path = 'D:/mallet-2.0.8/mallet-2.0.8/bin/mallet'\n",
        "    best_coh = 0\n",
        "    best_num = 0\n",
        "    best_top = ''\n",
        "    for i in range(start, number, rate):\n",
        "        print(i)\n",
        "        lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=i, \n",
        "                                           random_state=100,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)\n",
        "        # Show Topics\n",
        "        \n",
        "\n",
        "        # Compute Coherence Score\n",
        "        coherence_lda_model = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "        coherence_lda = coherence_lda_model.get_coherence()\n",
        "        #print('\\nCoherence Score: ', coherence_ldamallet)\n",
        "        if coherence_lda > best_coh:\n",
        "            best_coh = coherence_lda\n",
        "            best_num = i\n",
        "            best_model = lda_model\n",
        "            print(best_coh, best_num)\n",
        "\n",
        "    return (best_coh, best_num, best_model)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bRc-q1bPfFA"
      },
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcDxRQVh3Qnt",
        "outputId": "82dfde94-8bde-4da0-eac5-3e5ef1ed9c93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "choose_score(5, 30, 5, corpus, id2word, data_lemmatized)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "0.4297369063851419 5\n",
            "10\n",
            "0.4973497938960755 10\n",
            "15\n",
            "20\n",
            "25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4973497938960755, 10, <gensim.models.ldamodel.LdaModel at 0x7f85ac181240>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-trpwfFNWDP9"
      },
      "source": [
        "#счётчики для тем"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfM86zMwaTr6"
      },
      "source": [
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=10, \n",
        "                                           random_state=100,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ResdfVGUaZ3V"
      },
      "source": [
        "doc_lda = lda_model[corpus]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiZe7LsYa9lA"
      },
      "source": [
        " t = lda_model.print_topics()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z8nBN-ya-YX",
        "outputId": "74de2951-e987-4087-e53c-cadb68971197",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "list(t)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.028*\"team\" + 0.027*\"year\" + 0.026*\"game\" + 0.020*\"play\" + 0.018*\"win\" + 0.014*\"player\" + 0.010*\"run\" + 0.010*\"last\" + 0.009*\"good\" + 0.009*\"hit\"'),\n",
              " (1,\n",
              "  '0.022*\"go\" + 0.015*\"time\" + 0.013*\"day\" + 0.012*\"come\" + 0.011*\"take\" + 0.011*\"back\" + 0.011*\"get\" + 0.009*\"say\" + 0.008*\"see\" + 0.008*\"first\"'),\n",
              " (2,\n",
              "  '0.014*\"space\" + 0.008*\"cost\" + 0.008*\"year\" + 0.007*\"high\" + 0.007*\"research\" + 0.007*\"low\" + 0.006*\"item\" + 0.006*\"also\" + 0.006*\"test\" + 0.005*\"large\"'),\n",
              " (3,\n",
              "  '0.033*\"car\" + 0.021*\"drive\" + 0.013*\"bike\" + 0.011*\"power\" + 0.011*\"wire\" + 0.011*\"slave\" + 0.010*\"reality\" + 0.009*\"speed\" + 0.009*\"engine\" + 0.009*\"light\"'),\n",
              " (4,\n",
              "  '0.090*\"ax\" + 0.077*\"max\" + 0.018*\"di_di\" + 0.015*\"tumor\" + 0.012*\"homosexual\" + 0.011*\"gay\" + 0.009*\"taste\" + 0.008*\"liar\" + 0.007*\"marry\" + 0.006*\"homosexuality\"'),\n",
              " (5,\n",
              "  '0.017*\"government\" + 0.013*\"people\" + 0.012*\"gun\" + 0.011*\"state\" + 0.010*\"kill\" + 0.008*\"year\" + 0.007*\"public\" + 0.007*\"attack\" + 0.007*\"patient\" + 0.007*\"country\"'),\n",
              " (6,\n",
              "  '0.036*\"line\" + 0.017*\"thank\" + 0.015*\"host\" + 0.013*\"use\" + 0.013*\"problem\" + 0.011*\"get\" + 0.011*\"work\" + 0.011*\"need\" + 0.010*\"system\" + 0.010*\"window\"'),\n",
              " (7,\n",
              "  '0.033*\"would\" + 0.027*\"write\" + 0.018*\"article\" + 0.017*\"line\" + 0.016*\"know\" + 0.016*\"think\" + 0.016*\"make\" + 0.014*\"be\" + 0.012*\"may\" + 0.012*\"say\"'),\n",
              " (8,\n",
              "  '0.021*\"evidence\" + 0.013*\"believe\" + 0.013*\"reason\" + 0.010*\"faith\" + 0.010*\"say\" + 0.010*\"sense\" + 0.009*\"claim\" + 0.009*\"exist\" + 0.009*\"law\" + 0.008*\"physical\"'),\n",
              " (9,\n",
              "  '0.020*\"key\" + 0.018*\"program\" + 0.018*\"file\" + 0.013*\"information\" + 0.012*\"use\" + 0.010*\"system\" + 0.009*\"available\" + 0.008*\"source\" + 0.008*\"image\" + 0.008*\"include\"')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-aR_-MuceqQ"
      },
      "source": [
        "topic_dict = {}\n",
        "for topic in list(t):\n",
        "    topic = tuple(topic)\n",
        "    new_top = {}\n",
        "    for word in topic[1].split(' + '):\n",
        "        word = word.split('*')\n",
        "        new_top[word[1].strip('\\\"\\\"')] = float(word[0])\n",
        "    topic_dict[topic[0]] = new_top\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZpMSQbkgY0L",
        "outputId": "59279acb-2100-477b-ff66-af8ea296154a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "topic_dict[0]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'game': 0.026,\n",
              " 'good': 0.009,\n",
              " 'hit': 0.009,\n",
              " 'last': 0.01,\n",
              " 'play': 0.02,\n",
              " 'player': 0.014,\n",
              " 'run': 0.01,\n",
              " 'team': 0.028,\n",
              " 'win': 0.018,\n",
              " 'year': 0.027}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-DeEYFRh4Hd"
      },
      "source": [
        ""
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XouX7BbfV9w"
      },
      "source": [
        "text_topics = []\n",
        "for text in data_lemmatized:\n",
        "    count = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "    for word in text:\n",
        "        for topic, lemmas in topic_dict.items():\n",
        "            for lemm in lemmas:\n",
        "                if lemm == word:\n",
        "                    count[topic] += lemmas[lemm]\n",
        "    text_topics.append(count.index(max(count)))"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLvrhmDbkleS",
        "outputId": "bd4b1e2d-035f-4ce3-d0f5-c894a5826e05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(text_topics)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11314"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRy_CciFksKL",
        "outputId": "91a717b5-1214-48dd-9e9b-f44c7aeac76e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(data_lemmatized)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11314"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdzvzfbvl-9V"
      },
      "source": [
        "# TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RQGBiFOw4Ga"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTau-rxWnYqP"
      },
      "source": [
        "df_prefinal = pd.DataFrame()\n",
        "df_prefinal['texts'] = df['content']\n",
        "df_prefinal['lemmas'] = data_lemmatized\n",
        "df_prefinal['topics'] = text_topics\n",
        "df_prefinal['ind'] = [x for x in range(0,11314)]\n"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVTQtYwQzCiE",
        "outputId": "19b19644-47f8-4668-d633-f2301f322959",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "df_prefinal[:10]"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "      <th>lemmas</th>\n",
              "      <th>topics</th>\n",
              "      <th>ind</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
              "      <td>[where, thing, car, nntp_poste, host, park, li...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
              "      <td>[poll, final, call, summary, final, call, cloc...</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
              "      <td>[engineering, computer, network, distribution_...</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
              "      <td>[division, line, host, write, write, article, ...</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
              "      <td>[question, distribution, article, write, clear...</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>From: dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)\\...</td>\n",
              "      <td>[reword, idea, organization, article, tavare, ...</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>From: bmdelane@quads.uchicago.edu (brian manni...</td>\n",
              "      <td>[tumor, treatment, thank, line, people, respon...</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>From: bgrubb@dante.nmsu.edu (GRUBB)\\nSubject: ...</td>\n",
              "      <td>[scsi, state, nm, line, host, dante_nmsu, writ...</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>From: holmes7000@iscsvax.uni.edu\\nSubject: WIn...</td>\n",
              "      <td>[win, icon, help, please, line, win, download,...</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>From: kerr@ux1.cso.uiuc.edu (Stan Kerr)\\nSubje...</td>\n",
              "      <td>[stan_kerr, sigma_design, double, article, lin...</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               texts  ... ind\n",
              "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...  ...   0\n",
              "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...  ...   1\n",
              "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...  ...   2\n",
              "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...  ...   3\n",
              "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...  ...   4\n",
              "5  From: dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)\\...  ...   5\n",
              "6  From: bmdelane@quads.uchicago.edu (brian manni...  ...   6\n",
              "7  From: bgrubb@dante.nmsu.edu (GRUBB)\\nSubject: ...  ...   7\n",
              "8  From: holmes7000@iscsvax.uni.edu\\nSubject: WIn...  ...   8\n",
              "9  From: kerr@ux1.cso.uiuc.edu (Stan Kerr)\\nSubje...  ...   9\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVUh4k7Lm-mV"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzS7XsfA5RQx"
      },
      "source": [
        "df_1 = df_prefinal[df_prefinal['topics'] == 0]"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5A4WJrpo9zFi",
        "outputId": "2d789351-dc12-426c-e424-9763d9d790bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "df_1"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "      <th>lemmas</th>\n",
              "      <th>topics</th>\n",
              "      <th>ind</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\nS...</td>\n",
              "      <td>[insurance, rate, performance, car, line, late...</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>From: paul@csd4.csd.uwm.edu (Paul R Krueger)\\n...</td>\n",
              "      <td>[rock, division, line, nntp_poste, host, origi...</td>\n",
              "      <td>0</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>From: 18084TM@msu.edu (Tom)\\nSubject: Golden &amp;...</td>\n",
              "      <td>[age, added_forwarde, organization, distributi...</td>\n",
              "      <td>0</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208</th>\n",
              "      <td>From: seth@cbnewsh.cb.att.com (peter.r.clark.....</td>\n",
              "      <td>[flyer, year, big, worst_opinion, organization...</td>\n",
              "      <td>0</td>\n",
              "      <td>208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>From: dpeterik@iastate.edu (Dan Peterik)\\nSubj...</td>\n",
              "      <td>[line, write, know, brewer, s, back, team, mas...</td>\n",
              "      <td>0</td>\n",
              "      <td>256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11201</th>\n",
              "      <td>From: downec@crockett1a.its.rpi.edu (Christoph...</td>\n",
              "      <td>[year, next, year, playoff, line, let, fill, w...</td>\n",
              "      <td>0</td>\n",
              "      <td>11201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11220</th>\n",
              "      <td>From: Charles P. Cox, Jr. &lt;cox@snowhite.eeap.c...</td>\n",
              "      <td>[line, nntp_posting, host, xxdate, follow, sal...</td>\n",
              "      <td>0</td>\n",
              "      <td>11220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11231</th>\n",
              "      <td>From: Robert Angelo Pleshar &lt;rp16+@andrew.cmu....</td>\n",
              "      <td>[librarie, library, line, nntp_poste, host, pe...</td>\n",
              "      <td>0</td>\n",
              "      <td>11231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11266</th>\n",
              "      <td>From: pkortela@snakemail.hut.fi (Petteri Korte...</td>\n",
              "      <td>[petteri_kortelainen, new, finnish, bear, finl...</td>\n",
              "      <td>0</td>\n",
              "      <td>11266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11287</th>\n",
              "      <td>From: gballent@hudson.UVic.CA (Greg  Ballentin...</td>\n",
              "      <td>[wing, win, nntp_poste, host, ca, reply, line,...</td>\n",
              "      <td>0</td>\n",
              "      <td>11287</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>543 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   texts  ...    ind\n",
              "17     From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\nS...  ...     17\n",
              "43     From: paul@csd4.csd.uwm.edu (Paul R Krueger)\\n...  ...     43\n",
              "49     From: 18084TM@msu.edu (Tom)\\nSubject: Golden &...  ...     49\n",
              "208    From: seth@cbnewsh.cb.att.com (peter.r.clark.....  ...    208\n",
              "256    From: dpeterik@iastate.edu (Dan Peterik)\\nSubj...  ...    256\n",
              "...                                                  ...  ...    ...\n",
              "11201  From: downec@crockett1a.its.rpi.edu (Christoph...  ...  11201\n",
              "11220  From: Charles P. Cox, Jr. <cox@snowhite.eeap.c...  ...  11220\n",
              "11231  From: Robert Angelo Pleshar <rp16+@andrew.cmu....  ...  11231\n",
              "11266  From: pkortela@snakemail.hut.fi (Petteri Korte...  ...  11266\n",
              "11287  From: gballent@hudson.UVic.CA (Greg  Ballentin...  ...  11287\n",
              "\n",
              "[543 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aymf3uCl8HMJ",
        "outputId": "bb378b22-4390-424c-85fb-76bb8cb7888f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df_1['lemmas'].tolist()[0]"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['insurance',\n",
              " 'rate',\n",
              " 'performance',\n",
              " 'car',\n",
              " 'line',\n",
              " 'latech',\n",
              " 'newsreader_nnr',\n",
              " 'recently',\n",
              " 'post',\n",
              " 'article',\n",
              " 'ask',\n",
              " 'kind',\n",
              " 'rate',\n",
              " 'single',\n",
              " 'male',\n",
              " 'driver',\n",
              " 'yrs',\n",
              " 'old',\n",
              " 'pay',\n",
              " 'performance',\n",
              " 'car',\n",
              " 'here',\n",
              " 'summary',\n",
              " 'reply',\n",
              " 'receive',\n",
              " 'be',\n",
              " 'anymore',\n",
              " 'close',\n",
              " 'enough',\n",
              " 'twin',\n",
              " 'turbo',\n",
              " 'model',\n",
              " 'ticket',\n",
              " 'accident',\n",
              " 'take',\n",
              " 'defensive',\n",
              " 'driving',\n",
              " 'airbag',\n",
              " 'security',\n",
              " 'single',\n",
              " 'year',\n",
              " 'state',\n",
              " 'farm',\n",
              " 'insurance',\n",
              " 'include',\n",
              " 'additional',\n",
              " 'umbrella',\n",
              " 'policy',\n",
              " 'car',\n",
              " 'house',\n",
              " 'base',\n",
              " 'policy',\n",
              " 'standard',\n",
              " 'policy',\n",
              " 'require',\n",
              " 'defensive',\n",
              " 'drive',\n",
              " 'course',\n",
              " 'less',\n",
              " 'buy',\n",
              " 'car',\n",
              " 'company',\n",
              " 'never',\n",
              " 'accident',\n",
              " 'ticket',\n",
              " 'year',\n",
              " 'quote',\n",
              " 'hope',\n",
              " 'help',\n",
              " 'remember',\n",
              " 'name',\n",
              " 'correctly',\n",
              " 'ask',\n",
              " 'insurance',\n",
              " 'performance',\n",
              " 'car',\n",
              " 'well',\n",
              " 'last',\n",
              " 'year',\n",
              " 'similar',\n",
              " 'situation',\n",
              " 'buy',\n",
              " 'car',\n",
              " 'make',\n",
              " 'inquiry',\n",
              " 'age',\n",
              " 'car',\n",
              " 'drive',\n",
              " 'record',\n",
              " 'turn',\n",
              " 'may',\n",
              " 'insurance',\n",
              " 'go',\n",
              " 'mos',\n",
              " 'also',\n",
              " 'be',\n",
              " 'single',\n",
              " 'incur',\n",
              " 'high',\n",
              " 'rate',\n",
              " 'company',\n",
              " 'have',\n",
              " 'get',\n",
              " 'couple',\n",
              " 'friend',\n",
              " 'pay',\n",
              " 'different',\n",
              " 'in',\n",
              " 'company',\n",
              " 'also',\n",
              " 'maybe',\n",
              " 'be',\n",
              " 'lucky',\n",
              " 'hope',\n",
              " 'info',\n",
              " 'help',\n",
              " 'group',\n",
              " 'be',\n",
              " 'thunderbird',\n",
              " 'sc',\n",
              " 'never',\n",
              " 'make',\n",
              " 'claim',\n",
              " 'insurance',\n",
              " 'though',\n",
              " 'hit',\n",
              " 'several',\n",
              " 'time',\n",
              " 'negligent',\n",
              " 'driver',\n",
              " 'could',\n",
              " 'see',\n",
              " 'stop',\n",
              " 'sign',\n",
              " 'fiddle',\n",
              " 'radio',\n",
              " 'move',\n",
              " 'violation',\n",
              " 'last',\n",
              " 'month',\n",
              " 'go',\n",
              " 'failure',\n",
              " 'clear',\n",
              " 'intersection',\n",
              " 'still',\n",
              " 'say',\n",
              " 'damn',\n",
              " 'light',\n",
              " 'yellow',\n",
              " 'one',\n",
              " 'go',\n",
              " 'go',\n",
              " 'record',\n",
              " 'rate',\n",
              " 'state',\n",
              " 'passive',\n",
              " 'restraint',\n",
              " 'deduction',\n",
              " 'liability',\n",
              " 'deductible',\n",
              " 'comprehensive',\n",
              " 'deductible',\n",
              " 'collision',\n",
              " 'roughly',\n",
              " 'year',\n",
              " 'pay',\n",
              " 'year',\n",
              " 'disclaimer',\n",
              " 'be',\n",
              " 'engineer',\n",
              " 'play',\n",
              " 'work',\n",
              " 'hell',\n",
              " 'thing',\n",
              " 'kill',\n",
              " 'man',\n",
              " 'take',\n",
              " 'away',\n",
              " 's',\n",
              " 'ever',\n",
              " 'go',\n",
              " 'age',\n",
              " 'group',\n",
              " 'experience',\n",
              " 'may',\n",
              " 'interesting',\n",
              " 'own',\n",
              " 'decide',\n",
              " 'buy',\n",
              " 'gift',\n",
              " 'exotic',\n",
              " 'car',\n",
              " 'front',\n",
              " 'runner',\n",
              " 'include',\n",
              " 'model',\n",
              " 'year',\n",
              " 'narrow',\n",
              " 'like',\n",
              " 'simplicity',\n",
              " 'handling',\n",
              " 'snob',\n",
              " 'appeal',\n",
              " 'drive',\n",
              " 'turbo',\n",
              " 'less',\n",
              " 'money',\n",
              " 'feature',\n",
              " 'performance',\n",
              " 'almost',\n",
              " 'personal',\n",
              " 'luxury',\n",
              " 'car',\n",
              " 'well',\n",
              " 'acceleration',\n",
              " 'high',\n",
              " 'top',\n",
              " 'speed',\n",
              " 'almost',\n",
              " 'ready',\n",
              " 'give',\n",
              " 'buying',\n",
              " 'impulse',\n",
              " 'decide',\n",
              " 'stop',\n",
              " 'insurance',\n",
              " 'agent',\n",
              " 'office',\n",
              " 'way',\n",
              " 'ask',\n",
              " 'would',\n",
              " 'happen',\n",
              " 'rate',\n",
              " 'car',\n",
              " 'buy',\n",
              " 'rate',\n",
              " 'consider',\n",
              " 'year',\n",
              " 'rate',\n",
              " 'safe',\n",
              " 'car',\n",
              " 'slight',\n",
              " 'increase',\n",
              " 'car',\n",
              " 'year',\n",
              " 'new',\n",
              " 'low',\n",
              " 'risk',\n",
              " 'division',\n",
              " 'continue',\n",
              " 'handle',\n",
              " 'account',\n",
              " 'buy',\n",
              " 'change',\n",
              " 'standard',\n",
              " 'high',\n",
              " 'rate',\n",
              " 'company',\n",
              " 'rate',\n",
              " 'double',\n",
              " 'go',\n",
              " 'story',\n",
              " 'well',\n",
              " 'cover',\n",
              " 'rest',\n",
              " 'year',\n",
              " 'much',\n",
              " 'faster',\n",
              " 'actually',\n",
              " 'fast',\n",
              " 'standard',\n",
              " 'make',\n",
              " 'sense',\n",
              " 'book',\n",
              " 'say',\n",
              " 'insure',\n",
              " 'corvette',\n",
              " 'reason',\n",
              " 'underwriter',\n",
              " 'consider',\n",
              " 'supra',\n",
              " 'driver',\n",
              " 'traditional',\n",
              " 'conservative',\n",
              " 'eventually',\n",
              " 'go',\n",
              " 'number',\n",
              " 'reason',\n",
              " 'porsche',\n",
              " 'dealer',\n",
              " 'nice',\n",
              " 'salesman',\n",
              " 'get',\n",
              " 'interested',\n",
              " 'tough',\n",
              " 'high',\n",
              " 'pressure',\n",
              " 'guy',\n",
              " 'back',\n",
              " 'room',\n",
              " 'equal',\n",
              " 'monthly',\n",
              " 'payment',\n",
              " 'would',\n",
              " 'take',\n",
              " 'year',\n",
              " 'longer',\n",
              " 'pay',\n",
              " 'porsche',\n",
              " 'high',\n",
              " 'insurance',\n",
              " 'conclude',\n",
              " 'high',\n",
              " 'insurance',\n",
              " 'relate',\n",
              " 'probability',\n",
              " 'auto',\n",
              " 'theft',\n",
              " 'everyone',\n",
              " 'entitle',\n",
              " 'opinion',\n",
              " 'imagination',\n",
              " 'important',\n",
              " 'knowledge',\n",
              " 'live',\n",
              " 'idaho',\n",
              " 'many',\n",
              " 'year',\n",
              " 'buy',\n",
              " 'insurance',\n",
              " 'year',\n",
              " 'turn',\n",
              " 'immediately',\n",
              " 'drop',\n",
              " 'year',\n",
              " 'accident',\n",
              " 'strictly',\n",
              " 'age',\n",
              " 'change',\n",
              " 'rate',\n",
              " 'stay',\n",
              " 'pretty',\n",
              " 'much',\n",
              " 'sell',\n",
              " 'car',\n",
              " 'pickup',\n",
              " 'year',\n",
              " 'less',\n",
              " 'real',\n",
              " 'amazing',\n",
              " 'thing',\n",
              " 'wake',\n",
              " 'age',\n",
              " 'feel',\n",
              " 'much',\n",
              " 'responsible',\n",
              " 'information',\n",
              " 'single',\n",
              " 'move',\n",
              " 'violation',\n",
              " 'year',\n",
              " 'let',\n",
              " 'see',\n",
              " 'be',\n",
              " 'single',\n",
              " 'male',\n",
              " 'clean',\n",
              " 'driving',\n",
              " 'record',\n",
              " 'pay',\n",
              " 'year',\n",
              " 'good',\n",
              " 'deal',\n",
              " 'ask',\n",
              " 'think',\n",
              " 'get',\n",
              " 'talon',\n",
              " 'think',\n",
              " 'insurance',\n",
              " 'high',\n",
              " 'turbo',\n",
              " 'sport',\n",
              " 'car',\n",
              " 'clean',\n",
              " 'record',\n",
              " 'small',\n",
              " 'town',\n",
              " 'around',\n",
              " 'year',\n",
              " 'age',\n",
              " 'nearby',\n",
              " 'city',\n",
              " 'rate',\n",
              " 'higher',\n",
              " 'have',\n",
              " 'get',\n",
              " 'insure',\n",
              " 'protege',\n",
              " 'year',\n",
              " 'year',\n",
              " 'old',\n",
              " 'state',\n",
              " 'insurance',\n",
              " 'state',\n",
              " 'farm',\n",
              " 'info',\n",
              " 'car',\n",
              " 'co',\n",
              " 'insurance',\n",
              " 'yearly',\n",
              " 'insurance',\n",
              " 'age',\n",
              " 'date',\n",
              " 'license',\n",
              " 'mountain_view',\n",
              " 'move',\n",
              " 'violation',\n",
              " 'hope',\n",
              " 'help',\n",
              " 'post',\n",
              " 'summary',\n",
              " 'possible',\n",
              " 'vijay',\n",
              " 'email',\n",
              " 'single',\n",
              " 'year',\n",
              " 'old',\n",
              " 'turbo',\n",
              " 'full',\n",
              " 'cover',\n",
              " 'reasonable',\n",
              " 'liability',\n",
              " 'ticket',\n",
              " 'violation',\n",
              " 'accident',\n",
              " 'knock',\n",
              " 'wood',\n",
              " 'mass',\n",
              " 'thing',\n",
              " 'make',\n",
              " 'huge',\n",
              " 'difference',\n",
              " 'mass',\n",
              " 'town',\n",
              " 'live',\n",
              " 'be',\n",
              " 'personally',\n",
              " 'good',\n",
              " 'town',\n",
              " 'reasonable',\n",
              " 'distance',\n",
              " 'move',\n",
              " 'best',\n",
              " 'would',\n",
              " 'go',\n",
              " 'move',\n",
              " 'bad',\n",
              " 'would',\n",
              " 'also',\n",
              " 'accident',\n",
              " 'couple',\n",
              " 'ticket',\n",
              " 'would',\n",
              " 'probably',\n",
              " 'add',\n",
              " 'year',\n",
              " 'old',\n",
              " 'ticket',\n",
              " 'go',\n",
              " 'record',\n",
              " 'year',\n",
              " 'full',\n",
              " 'coverage',\n",
              " 'state',\n",
              " 'farm',\n",
              " 'get',\n",
              " 'small',\n",
              " 'discount',\n",
              " 'alarm',\n",
              " 'system',\n",
              " 'year',\n",
              " 'live',\n",
              " 'actually',\n",
              " 'live',\n",
              " 'city',\n",
              " 'price',\n",
              " 'would',\n",
              " 'year',\n",
              " 'be',\n",
              " 'case',\n",
              " 'be',\n",
              " 'interested',\n",
              " 'be',\n",
              " 'insure',\n",
              " 'month',\n",
              " 's',\n",
              " 'personal',\n",
              " 'total',\n",
              " 'property',\n",
              " 'deductible',\n",
              " 'glass',\n",
              " 'towing',\n",
              " 'state',\n",
              " 'farm',\n",
              " 'drive',\n",
              " 'less',\n",
              " 'year',\n",
              " 'think',\n",
              " 'seriously',\n",
              " 'rip',\n",
              " 'performance',\n",
              " 'car',\n",
              " 'list',\n",
              " 'record',\n",
              " 'clean',\n",
              " 'pay',\n",
              " 'try',\n",
              " 'call',\n",
              " 'insurance',\n",
              " 'dealer',\n",
              " 'could',\n",
              " 'find',\n",
              " 'rate',\n",
              " 'suppose',\n",
              " 'standardize',\n",
              " 'have',\n",
              " 'find',\n",
              " 'place',\n",
              " 'initially',\n",
              " 'call',\n",
              " 'give',\n",
              " 'ridiculously',\n",
              " 'high',\n",
              " 'hit',\n",
              " 'much',\n",
              " 'low',\n",
              " 'also',\n",
              " 'change',\n",
              " 'insurance_companie',\n",
              " 'rate',\n",
              " 'go',\n",
              " 'renewal',\n",
              " 'accident',\n",
              " 'ticket',\n",
              " 'car',\n",
              " 'get',\n",
              " 'old',\n",
              " 'maintain',\n",
              " 'low',\n",
              " 'rate',\n",
              " 'always',\n",
              " 'careful',\n",
              " 'come',\n",
              " 'insurance_companies',\n",
              " 'serge']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kJkhU29u5v0"
      },
      "source": [
        "all_topics = {}\n",
        "for i in range(10):\n",
        "    list_text = []\n",
        "    dict_of_topic = {}\n",
        "    df_1 = df_prefinal[df_prefinal['topics'] == i]\n",
        "    lemmas = df_1['lemmas'].tolist()\n",
        "    inds = df_1['ind'].tolist()\n",
        "    for num, t in enumerate(inds):\n",
        "        dict_of_topic[t] = lemmas[num]\n",
        "        list_text.append(' '.join(lemmas[num]))\n",
        "    vectors = vectorizer.fit_transform(list_text)\n",
        "    feature_names = vectorizer.get_feature_names()\n",
        "    dense = vectors.todense()\n",
        "    denselist = dense.tolist()\n",
        "    df = pd.DataFrame(denselist, columns=feature_names)\n",
        "    for text in df.index.tolist():\n",
        "        a = df[df[index] == text].tolist\n",
        "\n",
        "df.columns.tolist()\n",
        "\n",
        "    all_topics += dict_of_topic"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EkckGtsnTBM"
      },
      "source": [
        "for i in range(10):\n",
        "    list_texts = \n",
        "    vectors = vectorizer.fit_transform([documentA, documentB, documentC, documentD])\n",
        "    feature_names = vectorizer.get_feature_names()\n",
        "    dense = vectors.todense()\n",
        "    denselist = dense.tolist()\n",
        "    df = pd.DataFrame(denselist, columns=feature_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4MZy9ftcbUa"
      },
      "source": [
        ""
      ]
    }
  ]
}